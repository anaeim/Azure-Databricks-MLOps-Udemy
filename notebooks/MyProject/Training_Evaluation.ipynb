{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3842b705",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Databricks notebook source\n",
    "# Overview\n",
    "The MLflow Model Registry component is a centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of MLflow Models. It provides model lineage (which MLflow Experiment and Run produced the model), model versioning, stage transitions, annotations, and deployment management.\n",
    "\n",
    "In this notebook, you use each of the MLflow Model Registry's components to develop and manage a production machine learning application. This notebook covers the following topics:\n",
    "\n",
    "- Track and log models with MLflow\n",
    "- Register models with the Model Registry\n",
    "- Describe models and make model version stage transitions\n",
    "- Integrate registered models with production applications\n",
    "- Search and discover models in the Model Registry\n",
    "- Archive and delete models\n",
    "\n",
    "## Requirements\n",
    "- A cluster running Databricks Runtime 6.4 ML or above. Note that if your cluster is running Databricks Runtime 6.4 ML, you must upgrade the installed version of MLflow to 1.7.0. You can install this version from PyPI. See ([AWS](https://docs.databricks.com/libraries/cluster-libraries.html#cluster-installed-library)|[Azure](https://docs.microsoft.com/azure/databricks/libraries/cluster-libraries#cluster-installed-library)) for instructions. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bae7758",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Machine learning application: Forecasting wind power\n",
    "\n",
    "In this notebook, you use the MLflow Model Registry to build a machine learning application that forecasts the daily power output of a [wind farm](https://en.wikipedia.org/wiki/Wind_farm). Wind farm power output depends on weather conditions: generally, more energy is produced at higher wind speeds. Accordingly, the machine learning models used in the notebook predict power output based on weather forecasts with three features: `wind direction`, `wind speed`, and `air temperature`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23fecec6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "*This notebook uses altered data from the [National WIND Toolkit dataset](https://www.nrel.gov/grid/wind-toolkit.html) provided by NREL, which is publicly available and cited as follows:*\n",
    "\n",
    "*Draxl, C., B.M. Hodge, A. Clifton, and J. McCaa. 2015. Overview and Meteorological Validation of the Wind Integration National Dataset Toolkit (Technical Report, NREL/TP-5000-61740). Golden, CO: National Renewable Energy Laboratory.*\n",
    "\n",
    "*Draxl, C., B.M. Hodge, A. Clifton, and J. McCaa. 2015. \"The Wind Integration National Dataset (WIND) Toolkit.\" Applied Energy 151: 355366.*\n",
    "\n",
    "*Lieberman-Cribbin, W., C. Draxl, and A. Clifton. 2014. Guide to Using the WIND Toolkit Validation Code (Technical Report, NREL/TP-5000-62595). Golden, CO: National Renewable Energy Laboratory.*\n",
    "\n",
    "*King, J., A. Clifton, and B.M. Hodge. 2014. Validation of Power Output for the WIND Toolkit (Technical Report, NREL/TP-5D00-61714). Golden, CO: National Renewable Energy Laboratory.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b0b16",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "MAGIC %md ## Load the dataset\n",
    "MAGIC \n",
    "MAGIC The following cells load a dataset containing weather data and power output information for a wind farm in the United States. The dataset contains `wind direction`, `wind speed`, and `air temperature` features sampled every eight hours (once at `00:00`, once at `08:00`, and once at `16:00`), as well as daily aggregate power output (`power`), over several years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f56e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "I am changing the training code for a better version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcb516",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wind_farm_data = pd.read_csv(\"https://github.com/dbczumar/model-registry-demo-notebook/raw/master/dataset/windfarm_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219e97d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "  training_data = pd.DataFrame(wind_farm_data[\"2014-01-01\":\"2018-01-01\"])\n",
    "  X = training_data.drop(columns=\"power\")\n",
    "  y = training_data[\"power\"]\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5613f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_validation_data():\n",
    "  validation_data = pd.DataFrame(wind_farm_data[\"2018-01-01\":\"2019-01-01\"])\n",
    "  X = validation_data.drop(columns=\"power\")\n",
    "  y = validation_data[\"power\"]\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf3b36e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def get_weather_and_forecast():\n",
    "  format_date = lambda pd_date : pd_date.date().strftime(\"%Y-%m-%d\")\n",
    "  today = pd.Timestamp('today').normalize()\n",
    "  week_ago = today - pd.Timedelta(days=5)\n",
    "  week_later = today + pd.Timedelta(days=5)\n",
    "  \n",
    "  past_power_output = pd.DataFrame(wind_farm_data)[format_date(week_ago):format_date(today)]\n",
    "  weather_and_forecast = pd.DataFrame(wind_farm_data)[format_date(week_ago):format_date(week_later)]\n",
    "  if len(weather_and_forecast) < 10:\n",
    "    past_power_output = pd.DataFrame(wind_farm_data).iloc[-10:-5]\n",
    "    weather_and_forecast = pd.DataFrame(wind_farm_data).iloc[-10:]\n",
    "\n",
    "  return weather_and_forecast.drop(columns=\"power\"), past_power_output[\"power\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b720ef9e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Display a sample of the data for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e484fc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "wind_farm_data[\"2019-01-01\":\"2019-01-14\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5800da53",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Train a power forecasting model and track it with MLflow\n",
    "\n",
    "The following cells train a neural network to predict power output based on the weather features in the dataset. MLflow is used to track the model's hyperparameters, performance metrics, source code, and artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e5802c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "MAGIC %md Define a power forecasting model using TensorFlow Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063f3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44bad55",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def train_keras_model(X, y):\n",
    "  \n",
    "  model = Sequential()\n",
    "  model.add(Dense(100, input_shape=(X_train.shape[-1],), activation=\"relu\", name=\"hidden_layer\"))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "  model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=.2)\n",
    "  return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca16a3db",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Q. why do you need MLflow in databricks?\n",
    "\n",
    "\n",
    "You need **MLflow** in **Databricks** to **track, manage, and reproduce machine learning experiments** efficiently. Here's why it's useful, especially in a collaborative, production-ready environment:\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔍 1. Experiment Tracking\n",
    "MLflow automatically logs:\n",
    "- Parameters (e.g., learning rate, number of layers)\n",
    "- Metrics (e.g., accuracy, RMSE)\n",
    "- Artifacts (e.g., models, plots, datasets)\n",
    "- Code versions (linked to Git commits)\n",
    "\n",
    "> 💡 This helps you compare models easily and reproduce results later.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🏗️ 2. Model Management\n",
    "MLflow provides a **Model Registry**, where you can:\n",
    "- Register models\n",
    "- Assign stages (e.g., Staging, Production)\n",
    "- Track model versions\n",
    "- Roll back if something breaks\n",
    "\n",
    "> 💡 Think of it like version control for your ML models.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🚀 3. Deployment Made Easy\n",
    "MLflow supports multiple deployment targets out of the box:\n",
    "- Databricks serving endpoints\n",
    "- AWS SageMaker\n",
    "- Azure ML\n",
    "- Docker containers\n",
    "- REST APIs\n",
    "\n",
    "> 💡 You can deploy models without writing extra boilerplate code.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔁 4. Reproducibility\n",
    "Since MLflow tracks everything (code, data versions, parameters), you can rerun an old experiment and expect the same results.\n",
    "\n",
    "> 💡 Crucial for debugging and auditing models.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🤝 5. Team Collaboration\n",
    "In Databricks, experiments and models are shared within a workspace. Your team can:\n",
    "- View and compare each other's runs\n",
    "- Register and review models together\n",
    "- Comment and collaborate on model lifecycle\n",
    "\n",
    "> 💡 Great for cross-functional ML teams.\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ In short:\n",
    "> **MLflow in Databricks = streamlined ML workflow from training to production, with full traceability and collaboration.**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6e444d8",
   "metadata": {},
   "source": [
    "\n",
    "This code set the mflow to databricks model registery workspace (Run the using databricks CLI in Bash and make sure Databricks cli is installed) - you have to do this for all of your Dev, staging and prod workspaces.\n",
    "\n",
    "\n",
    "connect the current databricks to model registery databricks.<br>\n",
    "use the bash command lines below inside a databricks terminal.\n",
    "\n",
    "\n",
    "```bash\n",
    "databricks configure --token\n",
    "enter host (with worksapce id start with ?O)\n",
    "enter token of model dev workspace\n",
    "databricks secrets create-scope --scope modelregistery\n",
    "databricks secrets put --scope modelregistery --key modelregistery-token --string-value dapi5d4a1a907559461e73117957709bfbb6-2\n",
    "databricks secrets put --scope modelregistery --key modelregistery-workspace-id --string-value 8074051404611178\n",
    "databricks secrets put --scope modelregistery --key modelregistery-host --string-value https://adb-8074051404611178.18.azuredatabricks.net/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e08bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_uri = f'databricks://modelregistery:modelregistery'\n",
    "mlflow.set_registry_uri(registry_uri)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58335e2d",
   "metadata": {},
   "source": [
    "`registry_uri = f'databricks://modelregistery:modelregistery'`:\n",
    "\n",
    "This line is creating a Databricks URI that points to a MLFlow Model Registry.<br>\n",
    "this line is telling MLflow the address of MLFlow Model Registry-- central place is for storing and managing models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "551e7156",
   "metadata": {},
   "source": [
    "`mlflow.set_registry_uri(registry_uri)`:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "274877e7",
   "metadata": {},
   "source": [
    "### Q. what is MLFlow model registry?\n",
    "\n",
    "The MLflow Model Registry is a centralized store for managing the lifecycle of ML models. Think of it as a version-controlled hub where you can register, organize, track, and manage your machine learning models in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import mlflow.tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee087d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3b469",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "  # Automatically capture the model's parameters, metrics, artifacts,\n",
    "  # and source code with the `autolog()` function\n",
    "  mlflow.tensorflow.autolog()\n",
    "  \n",
    "  train_keras_model(X_train, y_train)\n",
    "  run_id = mlflow.active_run().info.run_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "852bf7e0",
   "metadata": {},
   "source": [
    "`with mlflow.start_run():`\n",
    "\n",
    "- Starts a new MLflow tracking run, which is a session for tracking everything (parameters, metrics, artifacts, etc.) during model training.\n",
    "- **Think of it as**: Opening a new experiment log book.\n",
    "- The with block ensures that the run is properly closed after training finishes.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "`mlflow.tensorflow.autolog()`:\n",
    "- Enables automatic logging for TensorFlow/Keras models.\n",
    "- **Think of it as**: Putting your logging on autopilot.\n",
    "- It automatically logs:\n",
    "  - Parameters (e.g., optimizer, learning rate)\n",
    "  - Metrics (e.g., loss, accuracy over epochs)\n",
    "  - Artifacts (e.g., model files, training graphs)\n",
    "  - Source code and environment info\n",
    "\n",
    "> 🔁 This removes the need to manually call mlflow.log_param(), mlflow.log_metric(), etc.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "`run_id = mlflow.active_run().info.run_id`\n",
    "- Retrieves the unique ID of the current MLflow run.\n",
    "- This ID can be used to:\n",
    "  - Reference the run later\n",
    "  - Register the trained model\n",
    "  - Access run artifacts programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e34028",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "run_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "112920ae",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Register the model with the MLflow Model Registry API\n",
    "\n",
    "Now that a forecasting model has been trained and tracked with MLflow, the next step is to register it with the MLflow Model Registry. You can register and manage models using the MLflow UI or the MLflow API .\n",
    "\n",
    "The following cells use the API to register your forecasting model, add rich model descriptions, and perform stage transitions. See the documentation for the UI workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af08bbb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model_name = \"power-forecasting-model\" # Replace this with the name of your registered model, if necessary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be002a15",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Create a new registered model using the API\n",
    "\n",
    "The following cells use the `mlflow.register_model()` function to create a new registered model whose name begins with the string `power-forecasting-model`. This also creates a new model version (for example, `Version 1` of `power-forecasting-model`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e301d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default path where the MLflow autologging function stores the model\n",
    "artifact_path = \"model\"\n",
    "model_uri = \"runs:/{run_id}/{artifact_path}\".format(run_id=run_id, artifact_path=artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d657468",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model_details = mlflow.register_model(model_uri=model_uri, name=model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6bbd5f5",
   "metadata": {},
   "source": [
    "## **NOTE**\n",
    "you can use unity catalogue to register your model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e79db89e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "After creating a model version, it may take a short period of time to become ready. Certain operations, such as model stage transitions, require the model to be in the `READY` state. Other operations, such as adding a description or fetching model details, can be performed before the model version is ready (for example, while it is in the `PENDING_REGISTRATION` state).\n",
    "\n",
    "The following cell uses the `MlflowClient.get_model_version()` function to wait until the model is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65eba0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "from mlflow.entities.model_registry.model_version_status import ModelVersionStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df512c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def wait_until_ready(model_name, model_version):\n",
    "  client = MlflowClient()\n",
    "  for _ in range(10):\n",
    "    model_version_details = client.get_model_version(\n",
    "      name=model_name,\n",
    "      version=model_version,\n",
    "    )\n",
    "    status = ModelVersionStatus.from_string(model_version_details.status)\n",
    "    print(\"Model status: %s\" % ModelVersionStatus.to_string(status))\n",
    "    if status == ModelVersionStatus.READY:\n",
    "      break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_until_ready(model_details.name, model_details.version)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
